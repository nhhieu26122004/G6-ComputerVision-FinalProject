# ğŸ¯ Káº¾ HOáº CH CHI TIáº¾T: PhÃ¢n loáº¡i rÃ¡c tháº£i thÃ´ng minh báº±ng YOLOv8

## ğŸ“Š TÃ“M Táº®T Váº¤N Äá»€

**Dá»± Ã¡n:** Há»‡ thá»‘ng phÃ¢n loáº¡i rÃ¡c tháº£i tá»± Ä‘á»™ng trong dÃ¢y chuyá»n xá»­ lÃ½ cÃ´ng nghiá»‡p

- **Deliverable:** Code hoÃ n chá»‰nh + BÃ¡o cÃ¡o chi tiáº¿t
- **Thá»i gian:** 3-4 ngÃ y
- **CÃ´ng nghá»‡:** YOLOv8 (Object Detection)
- **MÃ´i trÆ°á»ng:** Google Colab (Free GPU T4)
- **Dataset:** Nguá»“n cÃ´ng khai trÃªn máº¡ng
- **4 Classes:** Plastic (Nhá»±a), Metal (Kim loáº¡i), Paper (Giáº¥y), Glass (Thá»§y tinh)

---

## ğŸ—ºï¸ ROADMAP Tá»”NG THá»‚ (3-4 NGÃ€Y)

```
NgÃ y 1: [Task 1 + Task 2] â†’ Dataset + Setup
NgÃ y 2: [Task 3] â†’ Training Model
NgÃ y 3: [Task 4] â†’ Testing + Optimization
NgÃ y 4: [Task 5] â†’ BÃ¡o cÃ¡o + HoÃ n thiá»‡n
```

---

# ğŸ“¦ TASK 1: THU THáº¬P VÃ€ CHUáº¨N Bá»Š DATASET

## ğŸ”‘ Key Concepts

- **YOLO Format:** Annotation dáº¡ng `.txt` vá»›i format `class_id x_center y_center width height` (normalized 0-1)
- **Data Split:** Train/Valid/Test thÆ°á»ng theo tá»· lá»‡ 70/20/10 hoáº·c 80/10/10
- **Class Balance:** Äáº£m báº£o 4 lá»›p (Plastic/Metal/Paper/Glass) cÃ³ sá»‘ lÆ°á»£ng áº£nh tÆ°Æ¡ng Ä‘Æ°Æ¡ng
- **Data Augmentation:** YOLOv8 tá»± Ä‘á»™ng augment khi training

## ğŸ“ CÃ¡c bÆ°á»›c thá»±c hiá»‡n

### BÆ°á»›c 1.1: TÃ¬m kiáº¿m dataset cÃ´ng khai

**Nguá»“n Ä‘á» xuáº¥t:**

- **Roboflow Universe:** https://universe.roboflow.com (search "waste classification")
- **Kaggle:** Search "waste detection dataset" hoáº·c "garbage classification"
- **Specific Datasets:**
  - TrashNet Dataset
  - Waste Classification Data (Kaggle)
  - TACO Dataset (Trash Annotations in Context)

### BÆ°á»›c 1.2: Kiá»ƒm tra vÃ  táº£i dataset

Chá»n dataset cÃ³:

- âœ… Äá»§ 4 class: Plastic, Metal, Paper, Glass
- âœ… Format YOLO (hoáº·c cÃ³ thá»ƒ convert)
- âœ… Tá»‘i thiá»ƒu 500-1000 áº£nh
- âœ… Annotations cháº¥t lÆ°á»£ng cao

### BÆ°á»›c 1.3: Chuáº©n bá»‹ cáº¥u trÃºc thÆ° má»¥c

```
dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”œâ”€â”€ valid/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â””â”€â”€ data.yaml
```

### BÆ°á»›c 1.4: Táº¡o file `data.yaml`

```yaml
train: ./dataset/train/images
val: ./dataset/valid/images
test: ./dataset/test/images

nc: 4 # number of classes
names: ["Plastic", "Metal", "Paper", "Glass"]
```

### BÆ°á»›c 1.5: Upload lÃªn Google Drive

- Zip dataset vÃ  upload lÃªn Google Drive
- Äáº·t tÃªn rÃµ rÃ ng: `waste_detection_dataset.zip`

## ğŸ’¡ Gá»£i Ã½ & Code há»¯u Ã­ch

**Code kiá»ƒm tra dataset:**

```python
import os
import glob

# Äáº¿m sá»‘ áº£nh vÃ  labels
train_images = len(glob.glob('dataset/train/images/*'))
train_labels = len(glob.glob('dataset/train/labels/*'))
print(f"Train: {train_images} images, {train_labels} labels")

# Kiá»ƒm tra class distribution
class_counts = {0:0, 1:0, 2:0, 3:0}
for label_file in glob.glob('dataset/train/labels/*.txt'):
    with open(label_file, 'r') as f:
        for line in f:
            class_id = int(line.split()[0])
            class_counts[class_id] += 1

class_names = ['Plastic', 'Metal', 'Paper', 'Glass']
for i, count in class_counts.items():
    print(f"{class_names[i]}: {count} objects")
```

---

# âš™ï¸ TASK 2: THIáº¾T Láº¬P MÃ”I TRÆ¯á»œNG VÃ€ LÃ€M QUEN YOLOv8

## ğŸ”‘ Key Concepts

- **Ultralytics YOLOv8:** Library dá»… sá»­ dá»¥ng, high-level API
- **Pre-trained Weights:** Sá»­ dá»¥ng transfer learning tá»« COCO dataset
- **Model Sizes:** YOLOv8n (nano), s (small), m (medium), l (large), x (xlarge)
- **Google Colab GPU:** T4 GPU miá»…n phÃ­ (12-15GB RAM)

## ğŸ“ CÃ¡c bÆ°á»›c thá»±c hiá»‡n

### BÆ°á»›c 2.1: Táº¡o Google Colab Notebook

- Truy cáº­p https://colab.research.google.com
- Táº¡o notebook: `Waste_Classification_YOLOv8.ipynb`
- Enable GPU: `Runtime > Change runtime type > T4 GPU`

### BÆ°á»›c 2.2: CÃ i Ä‘áº·t YOLOv8

```python
# Install Ultralytics YOLOv8
!pip install ultralytics -q

# Import libraries
from ultralytics import YOLO
import torch
import os
from google.colab import drive
from IPython.display import Image, display

# Check GPU
print("GPU Available:", torch.cuda.is_available())
print("GPU Name:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "No GPU")
```

### BÆ°á»›c 2.3: Mount Google Drive vÃ  load dataset

```python
# Mount Drive
drive.mount('/content/drive')

# Unzip dataset
!unzip -q /content/drive/MyDrive/waste_detection_dataset.zip -d /content/

# Verify structure
!ls -la dataset/
```

### BÆ°á»›c 2.4: Test YOLOv8 vá»›i pretrained model

```python
# Load pretrained YOLOv8n
model = YOLO('yolov8n.pt')

# Test inference trÃªn 1 áº£nh máº«u
results = model.predict(source='dataset/train/images/sample_001.jpg', save=True)

# Hiá»ƒn thá»‹ káº¿t quáº£
display(Image('runs/detect/predict/sample_001.jpg'))
```

## ğŸ’¡ Hiá»ƒu vá» YOLOv8 cho ngÆ°á»i quen CNN

**So sÃ¡nh YOLOv8 vs CNN truyá»n thá»‘ng:**

- **CNN (Classification):** Input image â†’ Output class label (1 nhÃ£n)
- **YOLO (Detection):** Input image â†’ Output multiple [bbox, class, confidence] (nhiá»u objects)

**Kiáº¿n trÃºc YOLOv8 Ä‘Æ¡n giáº£n hÃ³a:**

```
Input Image (640x640)
    â†“
Backbone (CSPDarknet) - giá»‘ng CNN feature extractor
    â†“
Neck (FPN/PAN) - káº¿t há»£p features á»Ÿ nhiá»u scales
    â†“
Head (Detection) - predict [x, y, w, h, class probabilities]
```

---

# ğŸ“ TASK 3: TRAINING MODEL YOLOV8

## ğŸ”‘ Key Concepts

- **Transfer Learning:** Fine-tune tá»« pretrained weights (COCO dataset)
- **Epochs:** Sá»‘ láº§n model "há»c" toÃ n bá»™ dataset (50-100 epochs cho dataset nhá»)
- **Image Size (imgsz):** 640x640 lÃ  chuáº©n (cÃ³ thá»ƒ giáº£m xuá»‘ng 416 náº¿u GPU yáº¿u)
- **Batch Size:** Sá»‘ áº£nh xá»­ lÃ½ cÃ¹ng lÃºc (16-32 cho Colab T4)
- **Learning Rate:** Tá»‘c Ä‘á»™ há»c (YOLOv8 tá»± Ä‘á»™ng tune)

## ğŸ“ CÃ¡c bÆ°á»›c thá»±c hiá»‡n

### BÆ°á»›c 3.1: Chá»n model size phÃ¹ há»£p

**Khuyáº¿n nghá»‹ cho 3-4 ngÃ y:**

- `yolov8n.pt` (Nano): Fastest, 3.2M params - **Äá»€ XUáº¤T cho newbie**
- `yolov8s.pt` (Small): Balance, 11.2M params - Náº¿u muá»‘n accuracy cao hÆ¡n

### BÆ°á»›c 3.2: Cáº¥u hÃ¬nh training parameters

```python
from ultralytics import YOLO

# Load pretrained model
model = YOLO('yolov8n.pt')  # hoáº·c yolov8s.pt

# Training
results = model.train(
    data='dataset/data.yaml',      # Path to data.yaml
    epochs=100,                      # Sá»‘ epochs
    imgsz=640,                       # Image size
    batch=16,                        # Batch size (giáº£m xuá»‘ng 8 náº¿u OOM)
    patience=20,                     # Early stopping patience
    save=True,                       # Save checkpoints
    device=0,                        # GPU device (0 = first GPU)
    project='runs/waste_detection',  # Save location
    name='yolov8n_waste',           # Experiment name
    exist_ok=True,                   # Overwrite existing
    pretrained=True,                 # Use pretrained weights
    optimizer='AdamW',               # Optimizer
    verbose=True,                    # Print training info
    seed=42,                         # Reproducibility

    # Augmentation (cÃ³ thá»ƒ báº­t náº¿u dataset nhá»)
    hsv_h=0.015,                     # Hue augmentation
    hsv_s=0.7,                       # Saturation
    hsv_v=0.4,                       # Value
    degrees=10.0,                    # Rotation
    translate=0.1,                   # Translation
    scale=0.5,                       # Scaling
    flipud=0.0,                      # Flip up-down
    fliplr=0.5,                      # Flip left-right
    mosaic=1.0,                      # Mosaic augmentation
)
```

### BÆ°á»›c 3.3: Monitor training

```python
# Training sáº½ tá»± Ä‘á»™ng hiá»ƒn thá»‹:
# - Loss curves (box_loss, cls_loss, dfl_loss)
# - Metrics (Precision, Recall, mAP50, mAP50-95)
# - Validation results

# Sau khi training xong, xem results:
!ls runs/waste_detection/yolov8n_waste/

# File quan trá»ng:
# - weights/best.pt (model tá»‘t nháº¥t)
# - weights/last.pt (model cuá»‘i cÃ¹ng)
# - results.csv (metrics theo epochs)
# - confusion_matrix.png
```

### BÆ°á»›c 3.4: Visualize training results

```python
from IPython.display import Image

# Loss curves
display(Image('runs/waste_detection/yolov8n_waste/results.png'))

# Confusion matrix
display(Image('runs/waste_detection/yolov8n_waste/confusion_matrix.png'))

# Sample predictions
display(Image('runs/waste_detection/yolov8n_waste/val_batch0_pred.jpg'))
```

## ğŸ’¡ Tips Ä‘á»ƒ training hiá»‡u quáº£

**Náº¿u training bá»‹ Out of Memory (OOM):**

```python
# Giáº£m batch size
batch=8  # hoáº·c 4

# Hoáº·c giáº£m image size
imgsz=416  # thay vÃ¬ 640
```

**Theo dÃµi training tá»« xa (trÃ¡nh Colab disconnect):**

```python
# Sao lÆ°u weights Ä‘á»‹nh ká»³ vÃ o Drive
import shutil

# Sau má»—i 10 epochs, copy weights sang Drive
!cp runs/waste_detection/yolov8n_waste/weights/best.pt \
    /content/drive/MyDrive/yolov8_waste_backup.pt
```

---

# ğŸ§ª TASK 4: TESTING, EVALUATION VÃ€ OPTIMIZATION

## ğŸ”‘ Key Concepts

- **mAP (mean Average Precision):** Metric chÃ­nh cho object detection
  - mAP@0.5: IoU threshold = 0.5 (dá»… hÆ¡n)
  - mAP@0.5:0.95: IoU tá»« 0.5-0.95 (khÃ³ hÆ¡n, chuáº©n COCO)
- **Precision:** Tá»· lá»‡ predictions Ä‘Ãºng trong sá»‘ predictions (Ä‘á»™ chÃ­nh xÃ¡c)
- **Recall:** Tá»· lá»‡ objects Ä‘Æ°á»£c detect trong tá»•ng sá»‘ objects (Ä‘á»™ phá»§)
- **Confusion Matrix:** Ma tráº­n nháº§m láº«n giá»¯a cÃ¡c classes

## ğŸ“ CÃ¡c bÆ°á»›c thá»±c hiá»‡n

### BÆ°á»›c 4.1: Load model Ä‘Ã£ train

```python
# Load best model
model = YOLO('runs/waste_detection/yolov8n_waste/weights/best.pt')
```

### BÆ°á»›c 4.2: Evaluate trÃªn test set

```python
# Validation
metrics = model.val(
    data='dataset/data.yaml',
    split='test',           # Evaluate on test set
    imgsz=640,
    batch=16,
    save_json=True,         # Save COCO format results
    save_hybrid=True,       # Save labels + predictions
    conf=0.25,              # Confidence threshold
    iou=0.6,                # IoU threshold for NMS
    plots=True              # Generate plots
)

# Print metrics
print("\n=== EVALUATION RESULTS ===")
print(f"mAP@0.5: {metrics.box.map50:.4f}")
print(f"mAP@0.5:0.95: {metrics.box.map:.4f}")
print(f"Precision: {metrics.box.mp:.4f}")
print(f"Recall: {metrics.box.mr:.4f}")

# Per-class metrics
print("\n=== PER-CLASS METRICS ===")
class_names = ['Plastic', 'Metal', 'Paper', 'Glass']
for i, name in enumerate(class_names):
    print(f"{name}: mAP@0.5 = {metrics.box.maps[i]:.4f}")
```

### BÆ°á»›c 4.3: Test trÃªn áº£nh thá»±c táº¿

```python
# Predict trÃªn test images
results = model.predict(
    source='dataset/test/images',
    conf=0.25,              # Confidence threshold
    iou=0.6,                # IoU for NMS
    save=True,              # Save results
    save_txt=True,          # Save labels
    save_conf=True,         # Save confidence scores
    show_labels=True,       # Show labels
    show_conf=True,         # Show confidence
    line_width=2,           # Bounding box thickness
    project='runs/test',
    name='final_results'
)

# Hiá»ƒn thá»‹ má»™t sá»‘ káº¿t quáº£
import glob
test_results = glob.glob('runs/test/final_results/*.jpg')[:5]
for img_path in test_results:
    display(Image(img_path))
```

### BÆ°á»›c 4.4: Táº¡o demo video/stream (Optional)

```python
# Predict trÃªn video
results = model.predict(
    source='demo_video.mp4',
    save=True,
    stream=True,            # Stream results
    conf=0.3
)

# Hoáº·c webcam (náº¿u cÃ³)
# results = model.predict(source=0, show=True)
```

### BÆ°á»›c 4.5: Optimization - Tinh chá»‰nh threshold

```python
# Thá»­ nghiá»‡m vá»›i confidence threshold khÃ¡c nhau
confidence_thresholds = [0.1, 0.25, 0.5, 0.7]

for conf in confidence_thresholds:
    print(f"\n=== Testing with confidence = {conf} ===")
    metrics = model.val(
        data='dataset/data.yaml',
        conf=conf,
        plots=False
    )
    print(f"mAP@0.5: {metrics.box.map50:.4f}, Precision: {metrics.box.mp:.4f}, Recall: {metrics.box.mr:.4f}")
```

## ğŸ’¡ PhÃ¢n tÃ­ch káº¿t quáº£

**TiÃªu chÃ­ Ä‘Ã¡nh giÃ¡ tá»‘t cho bÃ i táº­p lá»›n:**

- âœ… **mAP@0.5 â‰¥ 0.70** (70%+): KhÃ¡ tá»‘t
- âœ… **mAP@0.5:0.95 â‰¥ 0.50** (50%+): Cháº¥p nháº­n Ä‘Æ°á»£c
- âœ… **Precision â‰¥ 0.75**: Ãt false positives
- âœ… **Recall â‰¥ 0.70**: PhÃ¡t hiá»‡n Ä‘Æ°á»£c Ä‘a sá»‘ objects

**Náº¿u káº¿t quáº£ chÆ°a tá»‘t:**

1. TÄƒng epochs (100 â†’ 150-200)
2. DÃ¹ng model lá»›n hÆ¡n (yolov8n â†’ yolov8s)
3. TÄƒng data augmentation
4. Kiá»ƒm tra láº¡i cháº¥t lÆ°á»£ng annotations

---

# ğŸ“ TASK 5: VIáº¾T BÃO CÃO VÃ€ HOÃ€N THIá»†N

## ğŸ”‘ Key Concepts

- **Reproducibility:** BÃ¡o cÃ¡o pháº£i Ä‘á»§ chi tiáº¿t Ä‘á»ƒ ngÆ°á»i khÃ¡c tÃ¡i hiá»‡n Ä‘Æ°á»£c
- **Visualization:** DÃ¹ng biá»ƒu Ä‘á»“, hÃ¬nh áº£nh minh há»a
- **Scientific Writing:** NgÃ´n ngá»¯ chuyÃªn nghiá»‡p, rÃµ rÃ ng
- **Code Documentation:** Comment code, README rÃµ rÃ ng

## ğŸ“ CÃ¡c bÆ°á»›c thá»±c hiá»‡n

### BÆ°á»›c 5.1: Cáº¥u trÃºc bÃ¡o cÃ¡o

**Má»¥c lá»¥c bÃ¡o cÃ¡o (8-15 trang):**

```markdown
1. GIá»šI THIá»†U
   1.1. Bá»‘i cáº£nh vÃ  Ä‘á»™ng lá»±c
   1.2. Má»¥c tiÃªu nghiÃªn cá»©u
   1.3. Pháº¡m vi Ä‘á» tÃ i

2. CÆ  Sá» LÃ THUYáº¾T
   2.1. Object Detection
   2.2. YOLO (You Only Look Once)
   2.3. YOLOv8 Architecture
   2.4. Transfer Learning

3. PHÆ¯Æ NG PHÃP THá»°C HIá»†N
   3.1. Dataset

   - Nguá»“n dá»¯ liá»‡u
   - Thá»‘ng kÃª dataset
   - Data preprocessing
     3.2. MÃ´i trÆ°á»ng thá»±c nghiá»‡m
     3.3. Cáº¥u hÃ¬nh training
     3.4. Evaluation metrics

4. Káº¾T QUáº¢ VÃ€ THáº¢O LUáº¬N
   4.1. Káº¿t quáº£ training

   - Loss curves
   - Metrics theo epochs
     4.2. Káº¿t quáº£ testing
   - mAP, Precision, Recall
   - Per-class performance
   - Confusion matrix
     4.3. Visualizations
     4.4. PhÃ¢n tÃ­ch vÃ  nháº­n xÃ©t

5. Káº¾T LUáº¬N VÃ€ HÆ¯á»šNG PHÃT TRIá»‚N
   5.1. TÃ³m táº¯t káº¿t quáº£
   5.2. Háº¡n cháº¿
   5.3. HÆ°á»›ng phÃ¡t triá»ƒn

6. TÃ€I LIá»†U THAM KHáº¢O

7. PHá»¤ Lá»¤C
   - Source code chÃ­nh
   - ThÃ´ng sá»‘ chi tiáº¿t
```

### BÆ°á»›c 5.2: Thu tháº­p tÃ i liá»‡u cho bÃ¡o cÃ¡o

**Artifacts cáº§n cÃ³:**

```python
# Táº¡o folder bÃ¡o cÃ¡o
!mkdir -p report_artifacts

# Copy cÃ¡c file quan trá»ng
!cp runs/waste_detection/yolov8n_waste/results.png report_artifacts/
!cp runs/waste_detection/yolov8n_waste/confusion_matrix.png report_artifacts/
!cp runs/waste_detection/yolov8n_waste/val_batch0_pred.jpg report_artifacts/
!cp runs/test/final_results/*.jpg report_artifacts/sample_predictions/

# Export metrics to CSV
import pandas as pd
metrics_df = pd.read_csv('runs/waste_detection/yolov8n_waste/results.csv')
metrics_df.to_excel('report_artifacts/training_metrics.xlsx', index=False)

# Zip toÃ n bá»™
!zip -r report_artifacts.zip report_artifacts/
```

### BÆ°á»›c 5.3: Viáº¿t cÃ¡c pháº§n chÃ­nh

**Section 1: Giá»›i thiá»‡u (1-2 trang)**

```markdown
## 1. GIá»šI THIá»†U

### 1.1. Bá»‘i cáº£nh vÃ  Ä‘á»™ng lá»±c

Trong bá»‘i cáº£nh Ã´ nhiá»…m mÃ´i trÆ°á»ng ngÃ y cÃ ng nghiÃªm trá»ng, viá»‡c phÃ¢n loáº¡i
vÃ  xá»­ lÃ½ rÃ¡c tháº£i hiá»‡u quáº£ trá»Ÿ thÃ nh váº¥n Ä‘á» cáº¥p thiáº¿t. Há»‡ thá»‘ng phÃ¢n loáº¡i
rÃ¡c tá»± Ä‘á»™ng sá»­ dá»¥ng thá»‹ giÃ¡c mÃ¡y tÃ­nh cÃ³ thá»ƒ giÃºp tá»‘i Æ°u hÃ³a quy trÃ¬nh
tÃ¡i cháº¿ trong cÃ¡c nhÃ  mÃ¡y xá»­ lÃ½ rÃ¡c...

### 1.2. Má»¥c tiÃªu nghiÃªn cá»©u

- XÃ¢y dá»±ng mÃ´ hÃ¬nh deep learning phÃ¡t hiá»‡n vÃ  phÃ¢n loáº¡i 4 loáº¡i rÃ¡c
- Äáº¡t Ä‘á»™ chÃ­nh xÃ¡c mAP@0.5 â‰¥ 70%
- á»¨ng dá»¥ng Ä‘Æ°á»£c trong mÃ´i trÆ°á»ng thá»±c táº¿ (dÃ¢y chuyá»n cÃ´ng nghiá»‡p)
```

**Section 2: CÆ¡ sá»Ÿ lÃ½ thuyáº¿t (2-3 trang)**

```markdown
## 2. CÆ  Sá» LÃ THUYáº¾T

### 2.2. YOLO (You Only Look Once)

YOLO lÃ  há» mÃ´ hÃ¬nh object detection sá»­ dá»¥ng approach "single-stage",
dá»± Ä‘oÃ¡n bounding boxes vÃ  class probabilities trá»±c tiáº¿p tá»« full image
trong má»™t láº§n forward pass. Äiá»u nÃ y giÃºp YOLO nhanh hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i
two-stage detectors nhÆ° R-CNN...

[ChÃ¨n hÃ¬nh: YOLO architecture diagram]

### 2.3. YOLOv8 Architecture

YOLOv8 (2023) lÃ  phiÃªn báº£n má»›i nháº¥t vá»›i nhá»¯ng cáº£i tiáº¿n:

- Backbone: CSPDarknet vá»›i C2f modules
- Neck: PAN (Path Aggregation Network)
- Head: Decoupled head (classification & localization riÃªng biá»‡t)
- Loss: VFL (Varifocal Loss) + CIoU loss

[ChÃ¨n cÃ´ng thá»©c toÃ¡n há»c náº¿u cáº§n]
```

**Section 4: Káº¿t quáº£ (3-4 trang)**

```markdown
## 4. Káº¾T QUáº¢ VÃ€ THáº¢O LUáº¬N

### 4.1. Káº¿t quáº£ Training

Model Ä‘Æ°á»£c training trong 100 epochs vá»›i early stopping patience = 20.
HÃ¬nh 4.1 thá»ƒ hiá»‡n sá»± há»™i tá»¥ cá»§a cÃ¡c loss functions vÃ  metrics.

[ChÃ¨n hÃ¬nh: results.png - loss curves vÃ  metrics]

Nháº­n xÃ©t:

- Loss giáº£m Ä‘á»u, khÃ´ng cÃ³ dáº¥u hiá»‡u overfitting
- mAP@0.5 Ä‘áº¡t 0.78 táº¡i epoch 87 (best)
- Precision vÃ  Recall cÃ¢n báº±ng (~0.75)

### 4.2. Káº¿t quáº£ Testing

Báº£ng 4.1: Performance metrics trÃªn test set

| Metric       | Value |
| ------------ | ----- |
| mAP@0.5      | 0.782 |
| mAP@0.5:0.95 | 0.534 |
| Precision    | 0.756 |
| Recall       | 0.724 |
| F1-Score     | 0.740 |

[ChÃ¨n hÃ¬nh: Confusion Matrix]

Báº£ng 4.2: Per-class Performance

| Class   | mAP@0.5 | Precision | Recall |
| ------- | ------- | --------- | ------ |
| Plastic | 0.812   | 0.789     | 0.756  |
| Metal   | 0.798   | 0.812     | 0.742  |
| Paper   | 0.745   | 0.701     | 0.698  |
| Glass   | 0.773   | 0.723     | 0.701  |

Nháº­n xÃ©t:

- Plastic vÃ  Metal Ä‘Æ°á»£c phÃ¡t hiá»‡n tá»‘t nháº¥t (Ä‘áº·c trÆ°ng rÃµ rÃ ng)
- Paper cÃ³ performance tháº¥p nháº¥t (dá»… nháº§m vá»›i background)
- Model hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh trÃªn cáº£ 4 classes

### 4.3. Visualizations

[ChÃ¨n 4-6 hÃ¬nh áº£nh predictions tá»‘t vÃ  cÃ³ issues]

HÃ¬nh 4.3: Má»™t sá»‘ trÆ°á»ng há»£p predictions thÃ nh cÃ´ng
HÃ¬nh 4.4: CÃ¡c trÆ°á»ng há»£p false positives vÃ  false negatives
```

### BÆ°á»›c 5.4: Tá»• chá»©c code vÃ  tÃ i liá»‡u

**Cáº¥u trÃºc folder submission:**

```
submission/
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ train.py                    # Training script
â”‚   â”œâ”€â”€ test.py                     # Testing script
â”‚   â”œâ”€â”€ inference.py                # Inference demo
â”‚   â””â”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ Waste_Classification_YOLOv8.ipynb
â”œâ”€â”€ report/
â”‚   â”œâ”€â”€ report.pdf                  # BÃ¡o cÃ¡o chÃ­nh
â”‚   â””â”€â”€ presentation.pptx           # Slides thuyáº¿t trÃ¬nh (náº¿u cáº§n)
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ weights/
â”‚   â”‚   â””â”€â”€ best.pt                 # Trained model
â”‚   â”œâ”€â”€ plots/                      # Visualizations
â”‚   â””â”€â”€ metrics/                    # CSV, logs
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ data.yaml                   # Dataset config (khÃ´ng upload áº£nh náº¿u lá»›n)
â””â”€â”€ README.md                       # HÆ°á»›ng dáº«n cháº¡y
```

**Template README.md:**

````markdown
# Waste Classification System using YOLOv8

## ğŸ“Œ Overview

Há»‡ thá»‘ng phÃ¢n loáº¡i rÃ¡c tháº£i tá»± Ä‘á»™ng sá»­ dá»¥ng YOLOv8 cho dÃ¢y chuyá»n xá»­ lÃ½ cÃ´ng nghiá»‡p.

## ğŸ¯ Performance

- **mAP@0.5:** 0.782
- **Precision:** 0.756
- **Recall:** 0.724
- **Classes:** Plastic, Metal, Paper, Glass

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```
````

### 2. Download Dataset

[Link to dataset hoáº·c hÆ°á»›ng dáº«n]

### 3. Training

```bash
python code/train.py --data dataset/data.yaml --epochs 100
```

### 4. Testing

```bash
python code/test.py --weights results/weights/best.pt
```

### 5. Inference

```bash
python code/inference.py --source path/to/image.jpg
```

## ğŸ“Š Results

[ChÃ¨n hÃ¬nh káº¿t quáº£ chÃ­nh]

## ğŸ‘¥ Team Members

- [TÃªn thÃ nh viÃªn 1]
- [TÃªn thÃ nh viÃªn 2]
- ...

## ğŸ“š References

1. Ultralytics YOLOv8: https://github.com/ultralytics/ultralytics
2. [Dataset source]
3. [Papers...]

````

### BÆ°á»›c 5.5: Code scripts chÃ­nh

**File: `code/train.py`**
```python
"""
Training script for Waste Classification using YOLOv8
"""
from ultralytics import YOLO
import argparse

def train(args):
    # Load model
    model = YOLO(args.model)

    # Train
    results = model.train(
        data=args.data,
        epochs=args.epochs,
        imgsz=args.imgsz,
        batch=args.batch,
        device=args.device,
        project=args.project,
        name=args.name,
        patience=20,
        save=True,
        pretrained=True,
        optimizer='AdamW',
        verbose=True,
        seed=42
    )

    print("Training completed!")
    print(f"Best model saved at: {args.project}/{args.name}/weights/best.pt")

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--model', type=str, default='yolov8n.pt', help='Model size')
    parser.add_argument('--data', type=str, required=True, help='Path to data.yaml')
    parser.add_argument('--epochs', type=int, default=100, help='Number of epochs')
    parser.add_argument('--imgsz', type=int, default=640, help='Image size')
    parser.add_argument('--batch', type=int, default=16, help='Batch size')
    parser.add_argument('--device', type=str, default='0', help='Device (0 or cpu)')
    parser.add_argument('--project', type=str, default='runs/train', help='Project path')
    parser.add_argument('--name', type=str, default='waste_yolov8', help='Experiment name')

    args = parser.parse_args()
    train(args)
````

**File: `code/test.py`**

```python
"""
Testing script for Waste Classification
"""
from ultralytics import YOLO
import argparse
import json

def test(args):
    # Load model
    model = YOLO(args.weights)

    # Validate
    metrics = model.val(
        data=args.data,
        split='test',
        imgsz=args.imgsz,
        batch=args.batch,
        conf=args.conf,
        iou=args.iou,
        save_json=True,
        plots=True
    )

    # Print results
    print("\n" + "="*50)
    print("EVALUATION RESULTS")
    print("="*50)
    print(f"mAP@0.5:      {metrics.box.map50:.4f}")
    print(f"mAP@0.5:0.95: {metrics.box.map:.4f}")
    print(f"Precision:    {metrics.box.mp:.4f}")
    print(f"Recall:       {metrics.box.mr:.4f}")
    print("="*50)

    # Save results
    results_dict = {
        'map50': float(metrics.box.map50),
        'map': float(metrics.box.map),
        'precision': float(metrics.box.mp),
        'recall': float(metrics.box.mr)
    }

    with open('test_results.json', 'w') as f:
        json.dump(results_dict, f, indent=4)

    print("\nResults saved to test_results.json")

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--weights', type=str, required=True, help='Path to trained weights')
    parser.add_argument('--data', type=str, required=True, help='Path to data.yaml')
    parser.add_argument('--imgsz', type=int, default=640, help='Image size')
    parser.add_argument('--batch', type=int, default=16, help='Batch size')
    parser.add_argument('--conf', type=float, default=0.25, help='Confidence threshold')
    parser.add_argument('--iou', type=float, default=0.6, help='IoU threshold')

    args = parser.parse_args()
    test(args)
```

**File: `code/inference.py`**

```python
"""
Inference script for single image/video
"""
from ultralytics import YOLO
import argparse
import cv2

def inference(args):
    # Load model
    model = YOLO(args.weights)

    # Predict
    results = model.predict(
        source=args.source,
        conf=args.conf,
        iou=args.iou,
        save=args.save,
        show=args.show,
        line_width=2,
        show_labels=True,
        show_conf=True
    )

    # Print detections
    class_names = ['Plastic', 'Metal', 'Paper', 'Glass']

    for i, r in enumerate(results):
        print(f"\n--- Image {i+1} ---")
        boxes = r.boxes
        for box in boxes:
            cls = int(box.cls[0])
            conf = float(box.conf[0])
            print(f"{class_names[cls]}: {conf:.2f}")

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--weights', type=str, required=True, help='Path to weights')
    parser.add_argument('--source', type=str, required=True, help='Image/video/directory path')
    parser.add_argument('--conf', type=float, default=0.25, help='Confidence threshold')
    parser.add_argument('--iou', type=float, default=0.6, help='IoU threshold')
    parser.add_argument('--save', action='store_true', help='Save results')
    parser.add_argument('--show', action='store_true', help='Show results')

    args = parser.parse_args()
    inference(args)
```

**File: `requirements.txt`**

```
ultralytics>=8.0.0
torch>=2.0.0
torchvision>=0.15.0
opencv-python>=4.8.0
numpy>=1.24.0
pandas>=2.0.0
matplotlib>=3.7.0
seaborn>=0.12.0
Pillow>=10.0.0
tqdm>=4.65.0
```

## ğŸ’¡ Tips viáº¿t bÃ¡o cÃ¡o chuyÃªn nghiá»‡p

### NgÃ´n ngá»¯ vÃ  trÃ¬nh bÃ y:

- âœ… Sá»­ dá»¥ng thuáº­t ngá»¯ tiáº¿ng Anh cho technical terms, giáº£i thÃ­ch tiáº¿ng Viá»‡t
- âœ… TrÃ­ch dáº«n papers vÃ  sources Ä‘áº§y Ä‘á»§ (IEEE/ACM format)
- âœ… ÄÃ¡nh sá»‘ hÃ¬nh, báº£ng, cÃ´ng thá»©c rÃµ rÃ ng
- âœ… Font chá»¯: Times New Roman 13pt, Calibri 12pt hoáº·c Arial 11pt
- âœ… Line spacing: 1.5

### Visualization tips:

```python
# Táº¡o publication-quality figures
import matplotlib.pyplot as plt
import seaborn as sns

# Set style
sns.set_style("whitegrid")
plt.rcParams['figure.dpi'] = 300  # High resolution
plt.rcParams['font.size'] = 12

# Example: Plot training metrics
import pandas as pd

metrics_df = pd.read_csv('runs/waste_detection/yolov8n_waste/results.csv')

fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# Loss curves
axes[0, 0].plot(metrics_df['train/box_loss'], label='Train Box Loss')
axes[0, 0].set_xlabel('Epoch')
axes[0, 0].set_ylabel('Loss')
axes[0, 0].set_title('Box Loss Over Time')
axes[0, 0].legend()
axes[0, 0].grid(True)

# mAP curves
axes[0, 1].plot(metrics_df['metrics/mAP50(B)'], label='mAP@0.5', color='green')
axes[0, 1].set_xlabel('Epoch')
axes[0, 1].set_ylabel('mAP')
axes[0, 1].set_title('mAP Over Time')
axes[0, 1].legend()
axes[0, 1].grid(True)

# Precision & Recall
axes[1, 0].plot(metrics_df['metrics/precision(B)'], label='Precision', color='blue')
axes[1, 0].plot(metrics_df['metrics/recall(B)'], label='Recall', color='orange')
axes[1, 0].set_xlabel('Epoch')
axes[1, 0].set_ylabel('Score')
axes[1, 0].set_title('Precision & Recall')
axes[1, 0].legend()
axes[1, 0].grid(True)

# F1 Score
f1_scores = 2 * (metrics_df['metrics/precision(B)'] * metrics_df['metrics/recall(B)']) / \
            (metrics_df['metrics/precision(B)'] + metrics_df['metrics/recall(B)'])
axes[1, 1].plot(f1_scores, label='F1-Score', color='red')
axes[1, 1].set_xlabel('Epoch')
axes[1, 1].set_ylabel('F1-Score')
axes[1, 1].set_title('F1-Score Over Time')
axes[1, 1].legend()
axes[1, 1].grid(True)

plt.tight_layout()
plt.savefig('report_artifacts/training_summary.png', dpi=300, bbox_inches='tight')
plt.show()
```

---

# âœ… TIÃŠU CHÃ ÄÃNH GIÃ CUá»I CÃ™NG (Acceptable Output Criteria)

## ğŸ“Š TiÃªu chÃ­ ká»¹ thuáº­t

### 1. Model Performance (40%)

- âœ… **mAP@0.5 â‰¥ 0.70** (Excellent: â‰¥0.80)
- âœ… **mAP@0.5:0.95 â‰¥ 0.45** (Excellent: â‰¥0.55)
- âœ… **Precision â‰¥ 0.70**
- âœ… **Recall â‰¥ 0.65**
- âœ… CÃ¡c class pháº£i balanced (khÃ´ng cÃ³ class nÃ o quÃ¡ kÃ©m)

### 2. Code Quality (20%)

- âœ… Code cháº¡y Ä‘Æ°á»£c, khÃ´ng lá»—i
- âœ… CÃ³ comments vÃ  docstrings rÃµ rÃ ng
- âœ… Cáº¥u trÃºc folder logic, dá»… hiá»ƒu
- âœ… README hÆ°á»›ng dáº«n Ä‘áº§y Ä‘á»§
- âœ… requirements.txt Ä‘áº§y Ä‘á»§ dependencies

### 3. BÃ¡o cÃ¡o (30%)

- âœ… Äáº§y Ä‘á»§ cÃ¡c pháº§n: Giá»›i thiá»‡u, LÃ½ thuyáº¿t, PhÆ°Æ¡ng phÃ¡p, Káº¿t quáº£, Káº¿t luáº­n
- âœ… CÃ³ visualizations (loss curves, confusion matrix, predictions)
- âœ… PhÃ¢n tÃ­ch káº¿t quáº£ sÃ¢u sáº¯c, khÃ´ng chá»‰ liá»‡t kÃª sá»‘ liá»‡u
- âœ… NgÃ´n ngá»¯ chuyÃªn nghiá»‡p, khÃ´ng lá»—i chÃ­nh táº£
- âœ… TrÃ­ch dáº«n Ä‘áº§y Ä‘á»§ (â‰¥5 tÃ i liá»‡u tham kháº£o)
- âœ… Format chuáº©n há»c thuáº­t (10-15 trang)

### 4. Presentation & Demo (10%)

- âœ… Slides trÃ¬nh bÃ y rÃµ rÃ ng (náº¿u cáº§n thuyáº¿t trÃ¬nh)
- âœ… Demo inference trÃªn áº£nh thá»±c táº¿
- âœ… Video demo ngáº¯n (1-2 phÃºt) - optional nhÆ°ng impressive

## ğŸ¯ Checklist trÆ°á»›c khi ná»™p

### Code Checklist:

- [ ] Code train.py cháº¡y Ä‘Æ°á»£c trÃªn Colab
- [ ] Code test.py cho ra káº¿t quáº£ Ä‘Ãºng
- [ ] Code inference.py demo Ä‘Æ°á»£c trÃªn áº£nh má»›i
- [ ] requirements.txt Ä‘áº§y Ä‘á»§
- [ ] README.md hÆ°á»›ng dáº«n rÃµ rÃ ng
- [ ] Model weights (best.pt) Ä‘Æ°á»£c lÆ°u

### BÃ¡o cÃ¡o Checklist:

- [ ] Trang bÃ¬a cÃ³ Ä‘áº§y Ä‘á»§ thÃ´ng tin (tÃªn Ä‘á» tÃ i, nhÃ³m, mÃ´n há»c)
- [ ] Má»¥c lá»¥c cÃ³ sá»‘ trang
- [ ] Táº¥t cáº£ hÃ¬nh/báº£ng cÃ³ caption vÃ  Ä‘Ã¡nh sá»‘
- [ ] Táº¥t cáº£ hÃ¬nh/báº£ng Ä‘Æ°á»£c refer trong text
- [ ] Pháº§n References format chuáº©n
- [ ] KhÃ´ng cÃ³ lá»—i chÃ­nh táº£
- [ ] File PDF dÆ°á»›i 20MB

### Results Checklist:

- [ ] Training converged (loss giáº£m, khÃ´ng diverge)
- [ ] mAP@0.5 â‰¥ 0.70
- [ ] Confusion matrix reasonable (khÃ´ng bias quÃ¡)
- [ ] Sample predictions cháº¥t lÆ°á»£ng tá»‘t
- [ ] Per-class metrics acceptable

---

# ğŸš€ TIPS THÃ€NH CÃ”NG

## Quáº£n lÃ½ thá»i gian 3-4 ngÃ y:

**NgÃ y 1 (8 giá»):**

- SÃ¡ng: TÃ¬m dataset, setup Colab, test YOLOv8 cÆ¡ báº£n (3h)
- Chiá»u: Chuáº©n bá»‹ dataset, táº¡o data.yaml, start training (3h)
- Tá»‘i: NghiÃªn cá»©u lÃ½ thuyáº¿t cho bÃ¡o cÃ¡o (2h)

**NgÃ y 2 (8 giá»):**

- SÃ¡ng: Monitor training, Ä‘iá»u chá»‰nh náº¿u cáº§n (2h)
- Chiá»u: Training xong, analyze results (3h)
- Tá»‘i: Viáº¿t pháº§n PhÆ°Æ¡ng phÃ¡p cá»§a bÃ¡o cÃ¡o (3h)

**NgÃ y 3 (8 giá»):**

- SÃ¡ng: Testing, optimization, táº¡o visualizations (4h)
- Chiá»u: Viáº¿t pháº§n Káº¿t quáº£ vÃ  Káº¿t luáº­n (3h)
- Tá»‘i: HoÃ n thiá»‡n code scripts (1h)

**NgÃ y 4 (6 giá»):**

- SÃ¡ng: Viáº¿t pháº§n Giá»›i thiá»‡u vÃ  LÃ½ thuyáº¿t (2h)
- Chiá»u: Review toÃ n bá»™, fix lá»—i, format bÃ¡o cÃ¡o (3h)
- Tá»‘i: Final check, export PDF, chuáº©n bá»‹ submission (1h)

## TrÃ¡nh nhá»¯ng sai láº§m thÆ°á»ng gáº·p:

âŒ **KHÃ”NG NÃŠN:**

- Training vá»›i quÃ¡ Ã­t epochs (< 50)
- Bá» qua viá»‡c validate model
- BÃ¡o cÃ¡o chá»‰ copy-paste lÃ½ thuyáº¿t khÃ´ng phÃ¢n tÃ­ch
- KhÃ´ng backup weights (Colab disconnect lÃ  máº¥t háº¿t)
- DÃ¹ng dataset quÃ¡ nhá» (< 300 áº£nh)

âœ… **NÃŠN:**

- Backup weights vÃ o Drive Ä‘á»‹nh ká»³
- Test nhiá»u confidence thresholds
- PhÃ¢n tÃ­ch cá»¥ thá»ƒ tá»«ng class performance
- ÄÆ°a vÃ­ dá»¥ cá»¥ thá»ƒ (áº£nh predictions)
- Thá»«a nháº­n limitations vÃ  Ä‘á» xuáº¥t improvements

## Resources há»¯u Ã­ch:

1. **YOLOv8 Documentation:** https://docs.ultralytics.com
2. **Roboflow Blog:** https://blog.roboflow.com (nhiá»u tutorials)
3. **Papers to cite:**
   - Original YOLO: Redmon et al., "You Only Look Once" (2016)
   - YOLOv8: Ultralytics YOLOv8 (2023)
4. **Dataset sources:**
   - Roboflow Universe: https://universe.roboflow.com
   - Kaggle Datasets: https://www.kaggle.com/datasets

---

# ğŸ“ TROUBLESHOOTING

## Váº¥n Ä‘á» thÆ°á»ng gáº·p:

### 1. Colab Out of Memory (OOM)

**Giáº£i phÃ¡p:**

```python
# Giáº£m batch size
batch=8  # hoáº·c 4

# Giáº£m image size
imgsz=416

# Restart runtime vÃ  clear cache
import torch
torch.cuda.empty_cache()
```

### 2. Colab Disconnect giá»¯a chá»«ng

**Giáº£i phÃ¡p:**

```python
# ThÃªm vÃ o Ä‘áº§u notebook:
from google.colab import drive
drive.mount('/content/drive')

# Trong training code:
# ThÃªm callback Ä‘á»ƒ save má»—i 10 epochs
callbacks = {
    'on_train_epoch_end': lambda: shutil.copy(
        'runs/.../weights/last.pt',
        '/content/drive/MyDrive/backup.pt'
    )
}
```

### 3. mAP quÃ¡ tháº¥p (< 0.50)

**NguyÃªn nhÃ¢n & giáº£i phÃ¡p:**

- Dataset quÃ¡ nhá» â†’ TÃ¬m dataset lá»›n hÆ¡n hoáº·c augment nhiá»u
- Annotations kÃ©m â†’ Kiá»ƒm tra láº¡i labels
- Training chÆ°a Ä‘á»§ â†’ TÄƒng epochs
- Model quÃ¡ nhá» â†’ DÃ¹ng yolov8s thay vÃ¬ yolov8n

### 4. Training khÃ´ng converge (loss khÃ´ng giáº£m)

**Kiá»ƒm tra:**

```python
# Verify data Ä‘Æ°á»£c load Ä‘Ãºng
from ultralytics import YOLO
model = YOLO('yolov8n.pt')

# Test trÃªn 1 batch
results = model.train(data='data.yaml', epochs=1, batch=1, imgsz=640)

# Náº¿u cháº¡y Ä‘Æ°á»£c â†’ tÄƒng dáº§n batch vÃ  epochs
```

---

# ğŸ“ Káº¾T LUáº¬N

Vá»›i káº¿ hoáº¡ch chi tiáº¿t nÃ y, báº¡n cÃ³ thá»ƒ hoÃ n thÃ nh bÃ i táº­p lá»›n trong 3-4 ngÃ y vá»›i cháº¥t lÆ°á»£ng tá»‘t.

**Key success factors:**

1. â° **Time management:** TuÃ¢n thá»§ timeline cháº·t cháº½
2. ğŸ” **Dataset quality:** Chá»n dataset tá»‘t ngay tá»« Ä‘áº§u
3. ğŸ’¾ **Backup:** LuÃ´n backup weights vÃ  code
4. ğŸ“Š **Analysis:** PhÃ¢n tÃ­ch káº¿t quáº£ sÃ¢u sáº¯c, khÃ´ng chá»‰ liá»‡t kÃª sá»‘
5. ğŸ“ **Documentation:** Code vÃ  bÃ¡o cÃ¡o rÃµ rÃ ng, chuyÃªn nghiá»‡p

**Expected final results:**

- Trained YOLOv8 model vá»›i mAP@0.5 ~ 0.75-0.85
- BÃ¡o cÃ¡o 10-15 trang cháº¥t lÆ°á»£ng cao
- Code base sáº¡ch sáº½, dá»… reproduce
- Demo impresssive vá»›i predictions chÃ­nh xÃ¡c

ChÃºc báº¡n thá»±c hiá»‡n project thÃ nh cÃ´ng! ğŸš€

---

**LÆ°u Ã½ cuá»‘i:** Document nÃ y lÃ  roadmap, trong quÃ¡ trÃ¬nh thá»±c hiá»‡n cÃ³ thá»ƒ cáº§n Ä‘iá»u chá»‰nh linh hoáº¡t dá»±a trÃªn káº¿t quáº£ thá»±c táº¿. Äá»«ng ngáº§n ngáº¡i experiment vÃ  tÃ¬m hiá»ƒu thÃªm!
