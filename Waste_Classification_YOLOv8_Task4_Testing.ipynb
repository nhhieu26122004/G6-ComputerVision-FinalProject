{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß™ Waste Classification using YOLOv8\n",
        "## TASK 4: TESTING & EVALUATION\n",
        "\n",
        "**Project:** Ph√¢n lo·∫°i r√°c th·∫£i th√¥ng minh  \n",
        "**Model:** Trained YOLOv8n (best.pt)  \n",
        "**Test Set:** ~198 images\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Prerequisites:\n",
        "- ‚úÖ Task 3 completed (model trained)\n",
        "- ‚úÖ Best weights available\n",
        "- ‚úÖ Test dataset ready\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß CELL 1: Setup & Load Best Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import and load best model\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import os\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "import pandas as pd\n",
        "\n",
        "print(\"üîß Loading trained model...\\n\")\n",
        "\n",
        "# Path to best weights\n",
        "best_weights = 'runs/waste_detection/yolov8n_waste/weights/best.pt'\n",
        "\n",
        "# Alternative: Load from Google Drive backup\n",
        "# best_weights = '/content/drive/MyDrive/Waste_Detection_Project/trained_models/yolov8n_waste_best.pt'\n",
        "\n",
        "if not os.path.exists(best_weights):\n",
        "    print(f\"‚ùå Model not found at: {best_weights}\")\n",
        "    print(\"Please check path or run Task 3 first!\")\n",
        "    raise FileNotFoundError(f\"Model not found: {best_weights}\")\n",
        "\n",
        "# Load model\n",
        "model = YOLO(best_weights)\n",
        "\n",
        "print(\"‚úÖ Model loaded successfully!\")\n",
        "print(f\"   Path: {best_weights}\")\n",
        "print(f\"   Classes: Plastic, Metal, Paper, Glass\")\n",
        "print(f\"   Ready for testing!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä CELL 2: Evaluate on Test Set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "print(\"üß™ Evaluating model on TEST SET...\\n\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "metrics = model.val(\n",
        "    data='/content/dataset/data.yaml',\n",
        "    split='test',\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    conf=0.25,\n",
        "    iou=0.6,\n",
        "    plots=True,\n",
        "    save_json=True\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üìä TEST SET RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nmAP@0.5:      {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5:0.95:  {metrics.box.map:.4f}\")\n",
        "print(f\"Precision:     {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall:        {metrics.box.mr:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üìã PER-CLASS METRICS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "class_names = ['Plastic', 'Metal', 'Paper', 'Glass']\n",
        "for i, name in enumerate(class_names):\n",
        "    print(f\"{name:10s}: mAP@0.5 = {metrics.box.maps[i]:.4f}\")\n",
        "\n",
        "print(\"\\n‚úÖ Evaluation completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üñºÔ∏è CELL 3: Test Predictions on Test Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run predictions on test set\n",
        "print(\"üñºÔ∏è Running predictions on test images...\\n\")\n",
        "\n",
        "results = model.predict(\n",
        "    source='/content/dataset/test/images',\n",
        "    conf=0.25,\n",
        "    iou=0.6,\n",
        "    save=True,\n",
        "    save_txt=True,\n",
        "    save_conf=True,\n",
        "    show_labels=True,\n",
        "    show_conf=True,\n",
        "    line_width=2,\n",
        "    project='runs/test',\n",
        "    name='final_results',\n",
        "    exist_ok=True\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Predictions completed!\")\n",
        "print(\"üìÅ Results saved at: runs/test/final_results/\")\n",
        "\n",
        "# Display sample predictions\n",
        "print(\"\\nüì∏ Sample predictions (first 6 images):\\n\")\n",
        "pred_images = sorted(glob.glob('runs/test/final_results/*.jpg'))[:6]\n",
        "\n",
        "for i, img_path in enumerate(pred_images, 1):\n",
        "    print(f\"--- Image {i} ---\")\n",
        "    display(Image(img_path, width=600))\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ‚úÖ TASK 4 COMPLETED!\n",
        "\n",
        "### üéâ Checklist:\n",
        "- ‚úÖ Best model loaded\n",
        "- ‚úÖ Evaluated on test set\n",
        "- ‚úÖ Metrics calculated (mAP, Precision, Recall)\n",
        "- ‚úÖ Per-class performance analyzed\n",
        "- ‚úÖ Predictions visualized\n",
        "\n",
        "### üìä Key Outputs:\n",
        "- Test metrics (mAP, Precision, Recall)\n",
        "- Per-class performance\n",
        "- Prediction visualizations\n",
        "- Confusion matrix\n",
        "\n",
        "### üìÅ Results Location:\n",
        "```\n",
        "runs/test/final_results/\n",
        "‚îú‚îÄ‚îÄ predictions/ (images with bounding boxes)\n",
        "‚îî‚îÄ‚îÄ labels/      (prediction labels)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ Next: TASK 5 - WRITE REPORT\n",
        "\n",
        "**S·ª≠ d·ª•ng template:** `BAO_CAO_TEMPLATE.md`\n",
        "\n",
        "**C·∫ßn ƒëi·ªÅn:**\n",
        "1. Dataset statistics\n",
        "2. Training configuration\n",
        "3. Training results (mAP, loss curves)\n",
        "4. Test results\n",
        "5. Sample predictions\n",
        "6. Conclusion\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
